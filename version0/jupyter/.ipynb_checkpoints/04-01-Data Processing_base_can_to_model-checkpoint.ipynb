{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知识点掌握要求：\n",
    " 数据处理的整个流程\n",
    " 第二节课的数据处理的内容，加上今天的一些数据处理的逻辑，最后构建整个模型的输入和标签，把整个串起来可以跑上模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "# 这里的意思就是可以通过在这里导入pycharm写好的包文件，然后实现jupyter直接读取\n",
    "# 这样就实现了将pycharm和jupyter的优势结合，享受pycharm的舒服的分块封装和jupyter的单步debug的模式\n",
    "# 最后再保存进pycharm\n",
    "# 要导入代码的路径 ,utils无法导入的同学,添加上自己code的路径 ,项目代码结构 code/utils ....\n",
    "# 将路径定位到自己的项目路径\n",
    "sys.path.append('D:/Learning/Project/QA/version1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_loader import build_dataset,pad_proc,sentences_proc\n",
    "from utils.config import *\n",
    "from utils.multi_proc_utils import parallelize\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_path)\n",
    "print(test_data_path)\n",
    "# 从这两个最原始的数据开始，一直到生成可以送进模型的训练集测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size 82943,test data size 20000\n"
     ]
    }
   ],
   "source": [
    "# 这里的路径就是通过from utils.config import *里边直接导入进来的\n",
    "# 直接使用pandas将数据读进来\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "print('train data size {},test data size {}'.format(len(train_df), len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Question</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰GL级</td>\n",
       "      <td>方向机重，助力泵，方向机都换了还是一样</td>\n",
       "      <td>技师说：[语音]|车主说：新的都换了|车主说：助力泵，方向机|技师说：[语音]|车主说：换了...</td>\n",
       "      <td>随时联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰M级</td>\n",
       "      <td>奔驰ML500排气凸轮轴调节错误</td>\n",
       "      <td>技师说：你这个有没有电脑检测故障代码。|车主说：有|技师说：发一下|车主说：发动机之前亮故障...</td>\n",
       "      <td>随时联系</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>宝马</td>\n",
       "      <td>宝马X1(进口)</td>\n",
       "      <td>2010款宝马X1，2011年出厂，2.0排量，通用6L45变速箱，原地换挡位PRND车辆闯...</td>\n",
       "      <td>技师说：你好，4缸自然吸气发动机N46是吧，先挂空档再挂其他档有没有闯动呢，变速箱油液位是否...</td>\n",
       "      <td>行驶没有顿挫的感觉，原地换挡有闯动，刹车踩重没有，这是力的限制的作用，应该没有问题</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>牧马人</td>\n",
       "      <td>3.0V6发动机号在什么位置，有照片最好！</td>\n",
       "      <td>技师说：右侧排气管上方，缸体上靠近变速箱|车主说：[图片]|车主说：是不是这个？|车主说：这...</td>\n",
       "      <td>举起车辆，在左前轮这边的缸体上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>奔驰</td>\n",
       "      <td>奔驰C级</td>\n",
       "      <td>2012款奔驰c180怎么样，维修保养，动力，值得拥有吗</td>\n",
       "      <td>技师说：家庭用车的话，还是可以入手的|技师说：维修保养费用不高|车主说：12年的180市场价...</td>\n",
       "      <td>家庭用车可以入手的，维修保养价格还可以。车况好，价格合理可以入手</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID Brand     Model                                           Question  \\\n",
       "0  Q1    奔驰     奔驰GL级                                方向机重，助力泵，方向机都换了还是一样   \n",
       "1  Q2    奔驰      奔驰M级                                   奔驰ML500排气凸轮轴调节错误   \n",
       "2  Q3    宝马  宝马X1(进口)  2010款宝马X1，2011年出厂，2.0排量，通用6L45变速箱，原地换挡位PRND车辆闯...   \n",
       "3  Q4  Jeep       牧马人                              3.0V6发动机号在什么位置，有照片最好！   \n",
       "4  Q5    奔驰      奔驰C级                       2012款奔驰c180怎么样，维修保养，动力，值得拥有吗   \n",
       "\n",
       "                                            Dialogue  \\\n",
       "0  技师说：[语音]|车主说：新的都换了|车主说：助力泵，方向机|技师说：[语音]|车主说：换了...   \n",
       "1  技师说：你这个有没有电脑检测故障代码。|车主说：有|技师说：发一下|车主说：发动机之前亮故障...   \n",
       "2  技师说：你好，4缸自然吸气发动机N46是吧，先挂空档再挂其他档有没有闯动呢，变速箱油液位是否...   \n",
       "3  技师说：右侧排气管上方，缸体上靠近变速箱|车主说：[图片]|车主说：是不是这个？|车主说：这...   \n",
       "4  技师说：家庭用车的话，还是可以入手的|技师说：维修保养费用不高|车主说：12年的180市场价...   \n",
       "\n",
       "                                      Report  \n",
       "0                                       随时联系  \n",
       "1                                       随时联系  \n",
       "2  行驶没有顿挫的感觉，原地换挡有闯动，刹车踩重没有，这是力的限制的作用，应该没有问题  \n",
       "3                            举起车辆，在左前轮这边的缸体上  \n",
       "4           家庭用车可以入手的，维修保养价格还可以。车况好，价格合理可以入手  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Question</th>\n",
       "      <th>Dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>大众(进口)</td>\n",
       "      <td>高尔夫(进口)</td>\n",
       "      <td>我的帕萨特烧机油怎么办怎么办？</td>\n",
       "      <td>技师说：你好，请问你的车跑了多少公里了，如果在保修期内，可以到当地的4店里面进行检查维修。如...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q2</td>\n",
       "      <td>一汽-大众奥迪</td>\n",
       "      <td>奥迪A6</td>\n",
       "      <td>修一下多少钱是换还是修</td>\n",
       "      <td>技师说：你好师傅！抛光处理一下就好了！50元左右就好了，希望能够帮到你！祝你生活愉快！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Q3</td>\n",
       "      <td>上汽大众</td>\n",
       "      <td>帕萨特</td>\n",
       "      <td>帕萨特领域    喇叭坏了  店里说方向盘里线坏了 换一根两三百不等 感觉太贵</td>\n",
       "      <td>技师说：你好，气囊油丝坏了吗，这个价格不贵。可以更换。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Q4</td>\n",
       "      <td>南京菲亚特</td>\n",
       "      <td>派力奥</td>\n",
       "      <td>发动机漏气会有什么征兆？</td>\n",
       "      <td>技师说：你好！一：发动机没力，并伴有“啪啪”的漏气声音。二：发动机没力，并伴有排气管冒黑烟。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Q5</td>\n",
       "      <td>东风本田</td>\n",
       "      <td>思铂睿</td>\n",
       "      <td>请问 那天右后胎扎了订，补了胎后跑高速80多开始有点抖，110时速以上抖动明显，以为是未做动...</td>\n",
       "      <td>技师说：你好师傅！可能前轮平衡快脱落或者不平衡造成的！建议前轮做一下动平衡就好了！希望能够帮...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID    Brand    Model                                           Question  \\\n",
       "0  Q1   大众(进口)  高尔夫(进口)                                    我的帕萨特烧机油怎么办怎么办？   \n",
       "1  Q2  一汽-大众奥迪     奥迪A6                                        修一下多少钱是换还是修   \n",
       "2  Q3     上汽大众      帕萨特           帕萨特领域    喇叭坏了  店里说方向盘里线坏了 换一根两三百不等 感觉太贵    \n",
       "3  Q4    南京菲亚特      派力奥                                       发动机漏气会有什么征兆？   \n",
       "4  Q5     东风本田      思铂睿  请问 那天右后胎扎了订，补了胎后跑高速80多开始有点抖，110时速以上抖动明显，以为是未做动...   \n",
       "\n",
       "                                            Dialogue  \n",
       "0  技师说：你好，请问你的车跑了多少公里了，如果在保修期内，可以到当地的4店里面进行检查维修。如...  \n",
       "1        技师说：你好师傅！抛光处理一下就好了！50元左右就好了，希望能够帮到你！祝你生活愉快！  \n",
       "2                        技师说：你好，气囊油丝坏了吗，这个价格不贵。可以更换。  \n",
       "3  技师说：你好！一：发动机没力，并伴有“啪啪”的漏气声音。二：发动机没力，并伴有排气管冒黑烟。...  \n",
       "4  技师说：你好师傅！可能前轮平衡快脱落或者不平衡造成的！建议前轮做一下动平衡就好了！希望能够帮...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 空值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里填充的时候会有一些方法，之前内容里边有\n",
    "train_df.dropna(subset=['Question', 'Dialogue', 'Report'], how='any', inplace=True)\n",
    "test_df.dropna(subset=['Question', 'Dialogue'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.多进程, 批量数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 这里进行多线程的处理，也是调用的from utils.multi_proc_utils import parallelize里边定义的函数\n",
    "train_df = parallelize(train_df, sentences_proc)\n",
    "test_df = parallelize(test_df, sentences_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 合并训练测试数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "这里是为了得到所有词的词向量，所有要将所有的词合在一起进行训练，主要是给word2vec使用，后边项目模型使用的时候还是要划分训练集、测试集、验证集的\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size 82871,test data size 20000,merged_df data size 102871\n"
     ]
    }
   ],
   "source": [
    "train_df['merged'] = train_df[['Question', 'Dialogue', 'Report']].apply(lambda x: ' '.join(x), axis=1)\n",
    "test_df['merged'] = test_df[['Question', 'Dialogue']].apply(lambda x: ' '.join(x), axis=1)\n",
    "merged_df = pd.concat([train_df[['merged']], test_df[['merged']]], axis=0)\n",
    "print('train data size {},test data size {},merged_df data size {}'.format(len(train_df), len(test_df),len(merged_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 保存处理好的 训练 测试集合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "由于上边为了方便word2vec训练，将训练集和测试集中的`'Question', 'Dialogue', 'Report'`都合并到一个子新的`'merged'`的列了，所以原始数据就发生变化了，这里将合并得到的`'merged'`列删掉，将预处理后的词向量进行一个单独的保存，方便后边项目模型使用\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['merged'], axis=1)\n",
    "test_df = test_df.drop(['merged'], axis=1)\n",
    "train_df.to_csv(train_seg_path, index=None, header=True)\n",
    "test_df.to_csv(test_seg_path, index=None, header=True)\n",
    "merged_df.to_csv(merger_seg_path, index=None, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 开始预训练词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = Word2Vec(LineSentence(merger_seg_path),\n",
    "                    size=300, \n",
    "                    negative=5, \n",
    "                    workers=12, \n",
    "                    iter=wv_train_epochs, \n",
    "                    window=3,\n",
    "                    min_count=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. 建立词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32801"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {word: index for index, word in enumerate(wv_model.wv.index2word)}\n",
    "reverse_vocab = {index: word for index, word in enumerate(wv_model.wv.index2word)}\n",
    "len(vocab)\n",
    "# 这里输出的只有三万多词，其他的应该就是和这三万多的词相同的词，训练集中的词会包括在vocab这个表之外的词，、\n",
    "# 所以应该将那些词填充成< unk >或者一个标志的形式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 1 .使用了min_count,其实部分词不在vocab表中 ,但是训练数据和测试数据中又有这些词该怎么办?\n",
    "---\n",
    "```\n",
    "将这部分词统一的填充为一个固定的标志或者词\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. 获取词向量矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32801, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = wv_model.wv.vectors\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 构建训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 可以把Question,Dialogue当做一句 `长文本处理`, 合并构建成X\n",
    "+ Report作为需要预测的标签,构建Y\n",
    "+ 整个项目的任务就是通过一个文本去预测另外一个文本，这里就是通过Question,Dialogue里边的文本来预测Report里边的文本--一个问答系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里的x就是Question,Dialogue合并之后的结果\n",
    "train_df['X'] = train_df[['Question', 'Dialogue']].apply(lambda x: ' '.join(x), axis=1)\n",
    "test_df['X'] = test_df[['Question', 'Dialogue']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    方向机 重 助力 泵 方向机 都 换 新 都 换 助力 泵 方向机 换 方向机 带 助力 重...\n",
       "1    奔驰 ML500 排气 凸轮轴 调节 错误 有没有 电脑 检测 故障 代码 有发 一下 发动...\n",
       "2    2010 款 宝马X1 2011 年 出厂 20 排量 通用 6L45 变速箱 原地 换挡 ...\n",
       "3    30V6 发动机 号 位置 照片 最好 右侧 排气管 上方 缸体 上 靠近 变速箱 是不是 ...\n",
       "4    2012 款 奔驰 c180 维修保养 动力 值得 拥有 家庭 用车 入手 维修保养 费用 ...\n",
       "Name: X, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['X'].head()\n",
    "# 输入的x的内容\n",
    "# 每一个输入的样本 x 就是这样的一段切分好的词(当然，真实输入到模型中的都是对应的id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        135\n",
       "1        205\n",
       "2        754\n",
       "3        202\n",
       "4        239\n",
       "        ... \n",
       "82938     52\n",
       "82939    220\n",
       "82940    301\n",
       "82941    324\n",
       "82942    446\n",
       "Name: X, Length: 82871, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = train_df['X'].apply(lambda x :len(x))\n",
    "lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "可以看出这里的句子长度都不一样，总不能输入的矩阵是一个三角形或者什么形状的矩阵吧，矩阵都是四四方方的，有以下方法：\n",
    "法一：选取最大的长度，但是这样的不能在长度悬殊很大的时候使用；比如两位数和四位数\n",
    "法二：可以试一下取中位数；或者满足90%；对句子排序再分batch，每个batch取最长的\n",
    "法三：见下边Q3，是传统的方法\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 2. 句子长度一样 ? 如何构建训练,batch操作,矩阵 ...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "对于这里的可变长度序列的处理，可以自己定义方法来解决吧这个问题，也可以使用TF/Keras里边定义好的处理可变长度处理的方法\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. 如何确定max_len的值? 经验 ?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 获取适当的Max_Len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里寻找max_len的目的就是为了使得得到的均值方方正正的，长的去掉一部分，短的填充\n",
    "`int(np.mean(data) + 2 * np.std(data))`  \n",
    "\n",
    "这里可以通过这样一个方法，<span class=\"burk\">统计一下所有数值的均值，再加上两倍的方差，这样的话如果你的数据符合正态分布\n",
    "那么这里最少可以覆盖到90%以上的数据，这样的话，我们就可以通过这样的方法来构建get_max_len函数,这样就可以找到一个比较合适的max_len</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(data):\n",
    "    \"\"\"\n",
    "    获得合适的最大长度值\n",
    "    :param data: 待统计的数据  train_df['Question']\n",
    "    :return: 最大长度值\n",
    "    \"\"\"\n",
    "    max_lens = data.apply(lambda x: x.count(' '))\n",
    "    return int(np.mean(max_lens) + 2 * np.std(max_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取输入数据 适当的最大长度\n",
    "# 由于这里训练集和测试集都有相应的数据，都有自己的max_len，但是最后要取一个，至于取哪一个可以有自己的方法\n",
    "# 因为你的模型使用训练集训练的，训练结束以后要使用测试集进行测试，所以这里前后的输入的shape应该是一样的\n",
    "train_y_max_len = get_max_len(train_df['X'])\n",
    "test_y_max_len = get_max_len(test_df['X'])\n",
    "\n",
    "x_max_len = max(train_y_max_len, test_y_max_len)\n",
    "\n",
    "# 获取标签数据 适当的最大长度\n",
    "train_y_max_len = get_max_len(train_df['Report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    随时 联系\n",
       "1                                                    随时 联系\n",
       "2          行驶 没有 顿挫 感觉 原地 换挡 闯动 刹车 踩 重 没有 力 限制 作用 应该 没有 问题\n",
       "3                                          举起 车辆 左 前轮 缸体 上\n",
       "4                          家庭 用车 入手 维修保养 价格 还 车况 好 价格合理 入手\n",
       "                               ...                        \n",
       "82938                                                查阅 资料\n",
       "82939    描述 1 车子 烧 机油 看 排气管 有没有 出现 蓝烟 检查 机油 有没有 少 2 油水 ...\n",
       "82940    这种 情况 需要 检查一下 底盘 护板 无异 响 进气道 翻板 电磁阀 无异 响 发动机 皮...\n",
       "82941    这种 情况 发动机 缸 内积 碳 清洗 一下 测量 一下 燃油 压力 是否 正常 缸 压 是...\n",
       "82942    这种 情况 需要 缸 内积 碳 清洗 一下 测量 燃油 压力 是否 正常 启动 马达 转动 ...\n",
       "Name: Report, Length: 82871, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集最大句子长度\n",
    "train_y_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试集最大句子长度\n",
    "x_max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 填充处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_proc(sentence, max_len, vocab):\n",
    "    '''\n",
    "    这段代码应该是在获取max_len之后的，但也无所谓，这是一个函数，只有调用的时候才会执行\n",
    "    这里传入的参数sentence是一个要处理的句子，这样的话每个句子循环调用这个函数就可以完成所有句子的处理\n",
    "    所有的句子都按照这样的方式处理\n",
    "    \n",
    "    这里传入的参数，处了sentence之外都是不用一次一次传的，是不动的，只需要每次往里边传入sentence即可\n",
    "    所以下边调用这个函数的时候只需要不断的传句子数据即可\n",
    "    < start > < end > < pad > < unk >\n",
    "    '''\n",
    "    # 0.按空格统计切分出词\n",
    "    words = sentence.strip().split(' ')\n",
    "    # 1. 截取规定长度的词数\n",
    "    words = words[:max_len]\n",
    "    # 2. 填充< unk > ,遍历这些词，判断是否在vocab中, 在就放到句子序列中，不在填充 < unk >\n",
    "    sentence = [word if word in vocab else '<UNK>' for word in words]\n",
    "    # 3. < unk >填充完了以后再填充一下开头和结尾< start > < end >\n",
    "    sentence = ['<START>'] + sentence + ['<STOP>']\n",
    "    # 4. 都填完了以后判断一下长度，看看是否达到规定的句子长度规定的最大长度，不到的话，填充　< pad >\n",
    "    sentence = sentence + ['<PAD>'] * (max_len + 2 - len(words))\n",
    "    return ' '.join(sentence)  # 最后将其拼接成一个字符串，再返回回去"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ < start > - 句子开始\n",
    "+ < end > - 句子结尾\n",
    "+ < pad > - 短句填充\n",
    "+ < unk > - 未知词  主要是因为处理数据建立vocab过程中过滤掉了低频词，即不在Embedding矩阵里边，所以要用< unk >进行填充。同时如果不填充直接删除的话会导致，原来不靠在一起，没有那么亲密关系的词靠在一起了，会对词的理解产生影响\n",
    "+ 这里的填充 `'<unk>'` 就是在训练的时候得到  `'<unk>'` 的词向量Embedding，这样遇到不在词表中的词的时候就将这个 `'<unk>'` 对应的Embedding传进去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集X处理\n",
    "# 对于这里得到apply，如果函数里边只需要传入一个参数的话，这里的lambda函数可以不写，直接丢一个函数名进去即可，会自动进行处理\n",
    "# 但是这里的函数pad_proc需要传入3个参数（要处理的数据，max_len, vocab）,后边的两个参数是不变的，变得只有前边的x\n",
    "train_df['X'] = train_df['X'].apply(lambda x: pad_proc(x, x_max_len, vocab))\n",
    "# 训练集Y处理\n",
    "train_df['Y'] = train_df['Report'].apply(lambda x: pad_proc(x, train_y_max_len, vocab))\n",
    "# 测试集X处理\n",
    "test_df['X'] = test_df['X'].apply(lambda x: pad_proc(x, x_max_len, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <START> 方向机 重 助力 泵 方向机 都 换 新 都 换 助力 泵 方向机 换 方向...\n",
       "1    <START> 奔驰 <UNK> 排气 凸轮轴 调节 错误 有没有 电脑 检测 故障 代码 ...\n",
       "2    <START> 2010 款 宝马X1 2011 年 出厂 20 排量 通用 <UNK> 变...\n",
       "3    <START> 30V6 发动机 号 位置 照片 最好 右侧 排气管 上方 缸体 上 靠近 ...\n",
       "4    <START> 2012 款 奔驰 c180 维修保养 动力 值得 拥有 家庭 用车 入手 ...\n",
       "Name: X, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['X'].head()\n",
    "# 这里边的<UNK>的多少和前边设置的min_count(词的频率)的大小有关，这里也要选恰当的值，好的选择可以在比赛等中取的好的效果\n",
    "# 处理后的数据展示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存中间结果数据  将上边处理好的数据的形式保存一下\n",
    "train_df['X'].to_csv(train_x_pad_path, index=None, header=False)\n",
    "train_df['Y'].to_csv(train_y_pad_path, index=None, header=False)\n",
    "test_df['X'].to_csv(test_x_pad_path, index=None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <START> 方向机 重 助力 泵 方向机 都 换 新 都 换 助力 泵 方向机 换 方向...\n",
       "1    <START> 奔驰 <UNK> 排气 凸轮轴 调节 错误 有没有 电脑 检测 故障 代码 ...\n",
       "2    <START> 2010 款 宝马X1 2011 年 出厂 20 排量 通用 <UNK> 变...\n",
       "Name: X, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['X'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'<START>' in vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "可以发现，'<START>'并不在vocab中，那么词向量矩阵中肯定也没有其对应的词向量，但是在训练的时候，输入的数据train_df['X']中却包含着'<START>'等\n",
    "```\n",
    "```\n",
    "解决方法：\n",
    "\n",
    "法一：使用自己自定义的向量来表示这些符号\n",
    "法二：像一开始跑没有加那些符号的数据的时候一样，使用Gensim这个工具将添加这些符号后的数据重新跑一下即可，这里不是一个重新训练整个模型的过程，而是一个增量训练的过程，训练好了之后保存，保存后vocab和词向量矩阵增大了，添加了四个符号的内容\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4 新加的符号不在词表 和 词向量矩阵中,怎么办?\n",
    "---\n",
    "- 这里合一进行一个更新，将这里新加的这几个符号`< start > < end > < pad > < unk >`放到词表中  \n",
    "- 使用Gensim里边的工具`build_vocab`这样的形式在原模型的基础上进行添加更新词表，相当于**增量训练**  \n",
    "重建之后重新保存一下模型  \n",
    "- 新得到的vocab中就包含了这几个添加的符号，后边的词向量矩阵中也就会含有它们对应的词向量Embedding\n",
    "- 如果一开始就将这些新加的符号和其他的词一起训练的话，因为这些符号的数量也不少，肯定会对相关词的词向量(语义表达)训练造成影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 词表更新\n",
    "词向量表的训练思路就是这样的：\n",
    "先训练一轮没有加特殊符号的词向量，然后将符号加进去之后，再去rebuild我们的vocab，和我们的词向量矩阵。这样的效果会更好一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start retrain w2v model')\n",
    "wv_model.build_vocab(LineSentence(train_x_pad_path), update=True)\n",
    "wv_model.train(LineSentence(train_x_pad_path), epochs=wv_train_epochs, \n",
    "               total_examples=wv_model.corpus_count)\n",
    "print('retrained 训练集的训练数据  进度达到1/3')\n",
    "wv_model.build_vocab(LineSentence(train_y_pad_path), update=True)\n",
    "wv_model.train(LineSentence(train_y_pad_path), epochs=wv_train_epochs, \n",
    "               total_examples=wv_model.corpus_count)\n",
    "print('retrained 训练集的测shi数据  进度达到2/3')\n",
    "wv_model.build_vocab(LineSentence(test_x_pad_path), update=True)\n",
    "wv_model.train(LineSentence(test_x_pad_path), epochs=wv_train_epochs, \n",
    "               total_examples=wv_model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:52:31,545 : INFO : saving Word2Vec object under D:\\Learning\\Project\\QA\\version1\\data\\wv\\word2vec.model, separately None\n",
      "2020-05-17 15:52:31,546 : INFO : not storing attribute vectors_norm\n",
      "2020-05-17 15:52:31,547 : INFO : not storing attribute cum_table\n",
      "2020-05-17 15:52:32,204 : INFO : saved D:\\Learning\\Project\\QA\\version1\\data\\wv\\word2vec.model\n"
     ]
    }
   ],
   "source": [
    "# 保存词向量模型\n",
    "wv_model.save(save_wv_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5.为什么不一开始就添加 标志符号,然后训练词向量?\n",
    "---\n",
    "一开始就把这些符号的话会影响别的词之间关系的理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32805, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#更新vocab\n",
    "vocab = {word: index for index, word in enumerate(wv_model.wv.index2word)}\n",
    "reverse_vocab = {index: word for index, word in enumerate(wv_model.wv.index2word)}\n",
    "# 更新词向量矩阵\n",
    "embedding_matrix = wv_model.wv.vectors\n",
    "embedding_matrix.shape\n",
    "# 可以看到新的词向量矩阵的shape,可以发现和之前的相比多了四个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6. 下边代码输出的处理好的词可以直接放入seq2seq模型中进行训练吗?\n",
    "---\n",
    "不可以，需要将文字全部转化为数值，然后构建一个矩阵去训练。\n",
    "一开始输入的是一个个具体的数字，然后用这些数字当做索引，去match对应矩阵中的那一行，得到相应的词向量\n",
    "所以这里的词向量矩阵是通vocab表建立的，因为它的index和词向量矩阵中的对应行相对应\n",
    "\n",
    "这里送进模型中进行训练的时候不是将下边的一个一个的词送进模型，而是将下边的词转换为一个一个的数字（index），送进模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <START> 方向机 重 助力 泵 方向机 都 换 新 都 换 助力 泵 方向机 换 方向...\n",
       "1    <START> 奔驰 <UNK> 排气 凸轮轴 调节 错误 有没有 电脑 检测 故障 代码 ...\n",
       "2    <START> 2010 款 宝马X1 2011 年 出厂 20 排量 通用 <UNK> 变...\n",
       "3    <START> 30V6 发动机 号 位置 照片 最好 右侧 排气管 上方 缸体 上 靠近 ...\n",
       "4    <START> 2012 款 奔驰 c180 维修保养 动力 值得 拥有 家庭 用车 入手 ...\n",
       "Name: X, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['X'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 数值转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遇到未知词就填充unk的索引\n",
    "# 这里由于是新来的一批数据，肯定也存在不在vocab里边的词，所以遇到不在的词也要填充unk\n",
    "unk_index = vocab['<UNK>']\n",
    "def transform_data(sentence,vocab):\n",
    "    # 字符串切分成词\n",
    "    words=sentence.split(' ')\n",
    "    # 按照vocab的index进行转换  ids:word_to_index\n",
    "    ids=[vocab[word] if word in vocab else unk_index for word in words]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将词转换成索引  [<START> 方向机 重 ...] -> [32800, 403, 986, 246, 231\n",
    "train_ids_x=train_df['X'].apply(lambda x:transform_data(x,vocab))\n",
    "train_ids_y=train_df['Y'].apply(lambda x:transform_data(x,vocab))\n",
    "test_ids_x=test_df['X'].apply(lambda x:transform_data(x,vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [32801, 403, 986, 246, 231, 403, 4, 9, 93, 4, ...\n",
       "1    [32801, 791, 32802, 388, 219, 362, 1607, 33, 2...\n",
       "2    [32801, 1452, 82, 7502, 1299, 63, 1143, 378, 6...\n",
       "3    [32801, 12624, 8, 307, 61, 522, 170, 938, 332,...\n",
       "4    [32801, 1368, 82, 791, 12625, 3287, 207, 2072,...\n",
       "Name: X, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_x.head()\n",
    "# 转换成数值输入的展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = train_ids_x.tolist()\n",
    "train_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将索引列表转换成矩阵 [32800, 403, 986, 246, 231] --> array([[32800,   403,   986 ]]\n",
    "# 这里转换成矩阵的思路就是：不转换成矩阵的话一个列表表示一句话，是分散的，是一维的，转换成矩阵的话，就是一个整体，是二维的，将训练集的训练数据\n",
    "# 所有模型接收的数据的维度都必须是二维或者二维以上的维度，文本数据的维度通常是二维\n",
    "# 训练集中的标签，测试集的数据分别放在一个矩阵中\n",
    "train_data_X=np.array(train_ids_x.tolist())  # 本身就是 list，list 套 list 就成了矩阵了\n",
    "train_data_Y=np.array(train_ids_y.tolist())\n",
    "test_data_X=np.array(test_ids_x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82871, 261)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32801,   403,   986, ..., 32804, 32804, 32804],\n",
       "       [32801,   791, 32802, ..., 32804, 32804, 32804],\n",
       "       [32801,  1452,    82, ..., 32804, 32804, 32804],\n",
       "       ...,\n",
       "       [32801,   210,   948, ..., 32804, 32804, 32804],\n",
       "       [32801, 12778,  3094, ..., 32804, 32804, 32804],\n",
       "       [32801,  2729,    63, ..., 32804, 32804, 32804]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 简易模型搭建\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq(input_length, output_sequence_length, embedding_matrix, vocab_size):\n",
    "    model = Sequential()\n",
    "    # 添加一个Embedding层\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=300, weights=[embedding_matrix], trainable=False,\n",
    "                        input_length=input_length))\n",
    "    # 添加一个双向的GRU层\n",
    "    model.add(Bidirectional(GRU(300, return_sequences=False)))\n",
    "    #添加一个Dense层\n",
    "    model.add(Dense(300, activation=\"relu\"))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    # 添加一个双向的GRU\n",
    "    model.add(Bidirectional(GRU(300, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(1e-3))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 基本参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82871, 261)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入的长度   x  max_len\n",
    "input_length = train_data_X.shape[1]\n",
    "# 输出的长度  y  max_len\n",
    "output_sequence_length = train_data_Y.shape[1]\n",
    "# 词表大小\n",
    "vocab_size=len(vocab)\n",
    "# 词向量矩阵\n",
    "embedding_matrix = wv_model.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 261, 300)          9841500   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 600)               1083600   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 34, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 34, 600)           1083600   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 34, 32805)         19715805  \n",
      "=================================================================\n",
      "Total params: 31,904,805\n",
      "Trainable params: 22,063,305\n",
      "Non-trainable params: 9,841,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 先盖楼\n",
    "model = seq2seq(input_length,output_sequence_length,embedding_matrix,vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82871, 261)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看一下矩阵的输入\n",
    "# 所有模型接收的数据的维度都必须是二维或者二维以上的维度，文本数据的维度通常是二维\n",
    "train_data_X.shape\n",
    "# 这里是八万多的数据，看下边batch_size是32，除以32是两千多次才能迭代结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66296 samples, validate on 16575 samples\n",
      "66296/66296 [==============================] - 330s 5ms/sample - loss: 3.1240 - val_loss: 2.8336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9e8e88508>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_X, train_data_Y, batch_size=32, epochs=1, validation_split=0.2)\n",
    "# 可以看到这里的输入数据：8万多个句子，每个句子的长度是261\n",
    "# 这也就是seq2seq模型数据输入维度是这样的原因，就是模型要求必须输入的维度是两维，又因为序列模型输入的是一个一个的句子，\n",
    "# 所以这里在输入之前将原本的一个一个的list变成了矩阵，达到了模型需要的两维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "root = pathlib.Path(os.path.abspath('__file__')).parent.parent\n",
    "save_seq2seq_model_path = os.path.join(root, 'data/11_try', 'seq2seq_model.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:42:36,144 : INFO : Assets written to: D:\\Learning\\Project\\QA\\version1\\data/11_try\\seq2seq_model.h\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(save_seq2seq_model_path)\n",
    "# D:/Learning/Project/QA/version1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
