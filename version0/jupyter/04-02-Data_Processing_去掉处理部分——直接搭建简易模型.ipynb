{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "# 要导入代码的路径 ,utils无法导入的同学,添加上自己code的路径 ,项目代码结构 code/utils ....\n",
    "sys.path.append('D:/Learning/Project/QA/version1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2020-05-17 16:44:58,149 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\17854\\AppData\\Local\\Temp\\jieba.cache\n",
      "2020-05-17 16:44:58,153 : DEBUG : Loading model from cache C:\\Users\\17854\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.622 seconds.\n",
      "2020-05-17 16:44:58,775 : DEBUG : Loading model cost 0.622 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2020-05-17 16:44:58,776 : DEBUG : Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.data_loader import build_dataset\n",
    "from utils.config import *\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size 82943, test data size 20000\n",
      "train data size 82871, test data size 20000, merged_df data size 102871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:48:41,437 : INFO : collecting all words and their counts\n",
      "2020-05-17 16:48:41,443 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start build w2v model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:48:41,683 : INFO : PROGRESS: at sentence #10000, processed 937177 words, keeping 36651 word types\n",
      "2020-05-17 16:48:41,912 : INFO : PROGRESS: at sentence #20000, processed 1888887 words, keeping 53935 word types\n",
      "2020-05-17 16:48:42,142 : INFO : PROGRESS: at sentence #30000, processed 2829348 words, keeping 66708 word types\n",
      "2020-05-17 16:48:42,375 : INFO : PROGRESS: at sentence #40000, processed 3741772 words, keeping 77609 word types\n",
      "2020-05-17 16:48:42,626 : INFO : PROGRESS: at sentence #50000, processed 4714531 words, keeping 87458 word types\n",
      "2020-05-17 16:48:42,891 : INFO : PROGRESS: at sentence #60000, processed 5748393 words, keeping 97382 word types\n",
      "2020-05-17 16:48:43,162 : INFO : PROGRESS: at sentence #70000, processed 6805782 words, keeping 106962 word types\n",
      "2020-05-17 16:48:43,406 : INFO : PROGRESS: at sentence #80000, processed 7747957 words, keeping 115065 word types\n",
      "2020-05-17 16:48:43,633 : INFO : PROGRESS: at sentence #90000, processed 8605811 words, keeping 122975 word types\n",
      "2020-05-17 16:48:43,850 : INFO : PROGRESS: at sentence #100000, processed 9455406 words, keeping 130010 word types\n",
      "2020-05-17 16:48:43,916 : INFO : collected 132023 word types from a corpus of 9704886 raw words and 102872 sentences\n",
      "2020-05-17 16:48:43,917 : INFO : Loading a fresh vocabulary\n",
      "2020-05-17 16:48:44,010 : INFO : effective_min_count=5 retains 32801 unique words (24% of original 132023, drops 99222)\n",
      "2020-05-17 16:48:44,010 : INFO : effective_min_count=5 leaves 9555787 word corpus (98% of original 9704886, drops 149099)\n",
      "2020-05-17 16:48:44,089 : INFO : deleting the raw counts dictionary of 132023 items\n",
      "2020-05-17 16:48:44,093 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-05-17 16:48:44,093 : INFO : downsampling leaves estimated 8595117 word corpus (89.9% of prior 9555787)\n",
      "2020-05-17 16:48:44,171 : INFO : estimated required memory for 32801 words and 300 dimensions: 95122900 bytes\n",
      "2020-05-17 16:48:44,172 : INFO : resetting layer weights\n",
      "2020-05-17 16:48:49,570 : INFO : training model with 8 workers on 32801 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=3\n",
      "2020-05-17 16:48:50,577 : INFO : EPOCH 1 - PROGRESS: at 16.75% examples, 1427917 words/s, in_qsize 0, out_qsize 2\n",
      "2020-05-17 16:48:51,579 : INFO : EPOCH 1 - PROGRESS: at 33.13% examples, 1415248 words/s, in_qsize 3, out_qsize 2\n",
      "2020-05-17 16:48:52,579 : INFO : EPOCH 1 - PROGRESS: at 50.38% examples, 1443528 words/s, in_qsize 14, out_qsize 0\n",
      "2020-05-17 16:48:53,586 : INFO : EPOCH 1 - PROGRESS: at 65.25% examples, 1430923 words/s, in_qsize 13, out_qsize 2\n",
      "2020-05-17 16:48:54,593 : INFO : EPOCH 1 - PROGRESS: at 82.74% examples, 1442755 words/s, in_qsize 9, out_qsize 2\n",
      "2020-05-17 16:48:55,494 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-05-17 16:48:55,501 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-05-17 16:48:55,502 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-05-17 16:48:55,513 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-05-17 16:48:55,516 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-05-17 16:48:55,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-05-17 16:48:55,525 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-05-17 16:48:55,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-05-17 16:48:55,529 : INFO : EPOCH - 1 : training on 9704886 raw words (8594890 effective words) took 6.0s, 1443439 effective words/s\n",
      "2020-05-17 16:48:55,529 : INFO : training on a 9704886 raw words (8594890 effective words) took 6.0s, 1442364 effective words/s\n",
      "2020-05-17 16:49:04,963 : INFO : collecting all words and their counts\n",
      "2020-05-17 16:49:04,967 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start retrain w2v model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:49:05,460 : INFO : PROGRESS: at sentence #10000, processed 2610000 words, keeping 22468 word types\n",
      "2020-05-17 16:49:05,962 : INFO : PROGRESS: at sentence #20000, processed 5220000 words, keeping 27518 word types\n",
      "2020-05-17 16:49:06,454 : INFO : PROGRESS: at sentence #30000, processed 7830000 words, keeping 29903 word types\n",
      "2020-05-17 16:49:06,958 : INFO : PROGRESS: at sentence #40000, processed 10440000 words, keeping 31157 word types\n",
      "2020-05-17 16:49:07,457 : INFO : PROGRESS: at sentence #50000, processed 13050000 words, keeping 31850 word types\n",
      "2020-05-17 16:49:07,956 : INFO : PROGRESS: at sentence #60000, processed 15660000 words, keeping 32303 word types\n",
      "2020-05-17 16:49:08,467 : INFO : PROGRESS: at sentence #70000, processed 18270000 words, keeping 32558 word types\n",
      "2020-05-17 16:49:08,968 : INFO : PROGRESS: at sentence #80000, processed 20880000 words, keeping 32658 word types\n",
      "2020-05-17 16:49:09,116 : INFO : collected 32684 word types from a corpus of 21629331 raw words and 82871 sentences\n",
      "2020-05-17 16:49:09,116 : INFO : Updating model with new vocabulary\n",
      "2020-05-17 16:49:09,135 : INFO : New added 27202 unique words (45% of original 59886) and increased the count of 27202 pre-existing words (45% of original 59886)\n",
      "2020-05-17 16:49:09,266 : INFO : deleting the raw counts dictionary of 32684 items\n",
      "2020-05-17 16:49:09,267 : INFO : sample=0.001 downsamples 18 most-common words\n",
      "2020-05-17 16:49:09,268 : INFO : downsampling leaves estimated 14299478 word corpus (66.2% of prior 21611626)\n",
      "2020-05-17 16:49:09,320 : INFO : estimated required memory for 54404 words and 300 dimensions: 157771600 bytes\n",
      "2020-05-17 16:49:09,320 : INFO : updating layer weights\n",
      "2020-05-17 16:49:09,354 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-05-17 16:49:09,356 : INFO : training model with 8 workers on 32805 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=3\n",
      "2020-05-17 16:49:10,367 : INFO : EPOCH 1 - PROGRESS: at 13.44% examples, 934038 words/s, in_qsize 13, out_qsize 2\n",
      "2020-05-17 16:49:11,367 : INFO : EPOCH 1 - PROGRESS: at 26.64% examples, 941569 words/s, in_qsize 13, out_qsize 2\n",
      "2020-05-17 16:49:12,368 : INFO : EPOCH 1 - PROGRESS: at 40.08% examples, 938148 words/s, in_qsize 13, out_qsize 3\n",
      "2020-05-17 16:49:13,380 : INFO : EPOCH 1 - PROGRESS: at 53.05% examples, 922629 words/s, in_qsize 9, out_qsize 0\n",
      "2020-05-17 16:49:14,383 : INFO : EPOCH 1 - PROGRESS: at 65.76% examples, 925335 words/s, in_qsize 13, out_qsize 0\n",
      "2020-05-17 16:49:15,386 : INFO : EPOCH 1 - PROGRESS: at 78.27% examples, 929614 words/s, in_qsize 16, out_qsize 0\n",
      "2020-05-17 16:49:16,388 : INFO : EPOCH 1 - PROGRESS: at 91.16% examples, 933125 words/s, in_qsize 0, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y, test_X, wv_model = build_dataset(train_data_path, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <START> 方向机 重 助力 泵 方向机 都 换 了 还是 一样 新 的 都 换 了 助...\n",
       "1    <START> 奔驰 <UNK> 排气 凸轮轴 调节 错误 你 这个 有没有 电脑 检测 故...\n",
       "2    <START> 2010 款 宝马X1 2011 年 出厂 20 排量 通用 <UNK> 变...\n",
       "3    <START> 30V6 发动机 号 在 什么 位置 有 照片 最好 右侧 排气管 上方 缸...\n",
       "4    <START> 2012 款 奔驰 c180 怎么样 维修保养 动力 值得 拥有 吗 家庭 ...\n",
       "Name: X, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获得 vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33234, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更新vocab \n",
    "vocab = {word: index for index, word in enumerate(wv_model.wv.index2word)}\n",
    "reverse_vocab = {index: word for index, word in enumerate(wv_model.wv.index2word)}\n",
    "# 更新词向量矩阵\n",
    "embedding_matrix = wv_model.wv.vectors\n",
    "embedding_matrix.shape#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['的',\n",
       " '了',\n",
       " '是',\n",
       " '有',\n",
       " '我',\n",
       " '这个',\n",
       " '就',\n",
       " '问题',\n",
       " '你',\n",
       " '可以',\n",
       " '吗',\n",
       " '不',\n",
       " '没有',\n",
       " '在',\n",
       " '也',\n",
       " '好',\n",
       " '都',\n",
       " '需要',\n",
       " '一下',\n",
       " '检查',\n",
       " '发动机',\n",
       " '什么',\n",
       " '换',\n",
       " '就是',\n",
       " '更换',\n",
       " '会',\n",
       " '正常',\n",
       " '和',\n",
       " '如果',\n",
       " '车',\n",
       " '情况',\n",
       " '用',\n",
       " '故障',\n",
       " '没',\n",
       " '机油',\n",
       " '说',\n",
       " '那',\n",
       " '还是',\n",
       " '去',\n",
       " '谢谢',\n",
       " '您',\n",
       " '吧',\n",
       " '要',\n",
       " '看',\n",
       " '对',\n",
       " '到',\n",
       " '把',\n",
       " '一个',\n",
       " '的话',\n",
       " '电脑',\n",
       " '这种',\n",
       " '现在',\n",
       " '这',\n",
       " '时候',\n",
       " '建议',\n",
       " '不会',\n",
       " '传感器',\n",
       " '可能',\n",
       " '声音',\n",
       " '变速箱',\n",
       " '应该',\n",
       " '清洗',\n",
       " '怎么',\n",
       " '有没有',\n",
       " '后',\n",
       " '还有',\n",
       " '啊',\n",
       " '过',\n",
       " '出现',\n",
       " '检查一下',\n",
       " '下',\n",
       " '上',\n",
       " '嗯',\n",
       " '能',\n",
       " '是否',\n",
       " '是不是',\n",
       " '或者',\n",
       " '节气门',\n",
       " '呢',\n",
       " '启动',\n",
       " '多少',\n",
       " '影响',\n",
       " '一般',\n",
       " '不是',\n",
       " '故障码',\n",
       " '还',\n",
       " '车子',\n",
       " '看看',\n",
       " '那个',\n",
       " '跑',\n",
       " '这样',\n",
       " '给',\n",
       " '公里',\n",
       " '左右',\n",
       " '很',\n",
       " '大',\n",
       " '做',\n",
       " '车辆',\n",
       " '然后',\n",
       " '火花塞',\n",
       " '油',\n",
       " '再',\n",
       " '师傅',\n",
       " '请问',\n",
       " '位置',\n",
       " '原因',\n",
       " '哦',\n",
       " '年',\n",
       " '开',\n",
       " '但是',\n",
       " '维修',\n",
       " '保养',\n",
       " '一样',\n",
       " '比较',\n",
       " '感觉',\n",
       " '行驶',\n",
       " '知道',\n",
       " '线路',\n",
       " '才',\n",
       " '里面',\n",
       " '时',\n",
       " '导致',\n",
       " '先',\n",
       " '轮胎',\n",
       " '4s店',\n",
       " '又',\n",
       " '不好',\n",
       " '开关',\n",
       " '压力',\n",
       " '款',\n",
       " '他',\n",
       " '电瓶',\n",
       " '怠速',\n",
       " '刹车',\n",
       " '坏',\n",
       " '空调',\n",
       " '拆',\n",
       " '修理厂',\n",
       " '不能',\n",
       " '使用',\n",
       " '多',\n",
       " '点火',\n",
       " '新',\n",
       " '根据',\n",
       " '大师',\n",
       " '造成',\n",
       " '个',\n",
       " '抖动',\n",
       " '汽油',\n",
       " '钥匙',\n",
       " '地方',\n",
       " '检测',\n",
       " '系统',\n",
       " '着',\n",
       " '钱',\n",
       " '进行',\n",
       " '灯',\n",
       " '两个',\n",
       " '万公里',\n",
       " '显示',\n",
       " '熄火',\n",
       " '不行',\n",
       " '以后',\n",
       " '大概',\n",
       " '不客气',\n",
       " '直接',\n",
       " '插头',\n",
       " '出来',\n",
       " '上面',\n",
       " '工作',\n",
       " '买',\n",
       " '解决',\n",
       " '控制',\n",
       " '匹配',\n",
       " '找',\n",
       " '加',\n",
       " '打开',\n",
       " '档',\n",
       " '喷油嘴',\n",
       " '高',\n",
       " '缸',\n",
       " '自己',\n",
       " '一点',\n",
       " '现象',\n",
       " '跟',\n",
       " '想',\n",
       " '线',\n",
       " '因为',\n",
       " '关系',\n",
       " '试试',\n",
       " '哪里',\n",
       " '得',\n",
       " '一直',\n",
       " '其他',\n",
       " '等',\n",
       " '处理',\n",
       " '汽车',\n",
       " '加油',\n",
       " '肯定',\n",
       " '水温',\n",
       " '让',\n",
       " '离合器',\n",
       " '起来',\n",
       " '主要',\n",
       " '1',\n",
       " '之前',\n",
       " '踩',\n",
       " '从',\n",
       " '不用',\n",
       " '2',\n",
       " '一次',\n",
       " '有点',\n",
       " '异响',\n",
       " '来',\n",
       " '挂',\n",
       " '皮带',\n",
       " '方向盘',\n",
       " '仪表',\n",
       " '具体',\n",
       " '螺丝',\n",
       " '损坏',\n",
       " '么',\n",
       " '气门',\n",
       " '时间',\n",
       " '自动',\n",
       " '怎么回事',\n",
       " '之后',\n",
       " '转',\n",
       " '不了',\n",
       " '他们',\n",
       " '东西',\n",
       " '只有',\n",
       " '所以',\n",
       " '油耗',\n",
       " '问',\n",
       " '没事',\n",
       " '模块',\n",
       " '最好',\n",
       " '价格',\n",
       " '打',\n",
       " '原厂',\n",
       " '4S店',\n",
       " '响',\n",
       " '只能',\n",
       " '积碳',\n",
       " '亮',\n",
       " '转速',\n",
       " '200',\n",
       " '油门',\n",
       " '安装',\n",
       " '重新',\n",
       " '确定',\n",
       " '这是',\n",
       " '方向',\n",
       " '数据',\n",
       " '今天',\n",
       " '空气',\n",
       " '防冻液',\n",
       " '只要',\n",
       " '描述',\n",
       " '但',\n",
       " '进气',\n",
       " '信号',\n",
       " '为',\n",
       " '咨询',\n",
       " '它',\n",
       " '高速',\n",
       " '小',\n",
       " '保险',\n",
       " '已经',\n",
       " '拆下来',\n",
       " '我们',\n",
       " '3',\n",
       " '一',\n",
       " '水箱',\n",
       " '点',\n",
       " '发现',\n",
       " '后面',\n",
       " '线圈',\n",
       " '底盘',\n",
       " '以前',\n",
       " '动力',\n",
       " '下面',\n",
       " '0',\n",
       " '新车',\n",
       " '4',\n",
       " '正时',\n",
       " '解答',\n",
       " '出',\n",
       " '中',\n",
       " '这款',\n",
       " '修',\n",
       " '按',\n",
       " '那么',\n",
       " '门',\n",
       " '凸轮轴',\n",
       " '测量',\n",
       " '不要',\n",
       " '刹车片',\n",
       " '定位',\n",
       " '呀',\n",
       " '冷车',\n",
       " '磨损',\n",
       " '油泵',\n",
       " '电机',\n",
       " '滤芯',\n",
       " '温度',\n",
       " '轴承',\n",
       " '泵',\n",
       " '前',\n",
       " '继电器',\n",
       " '哪个',\n",
       " '明显',\n",
       " '店',\n",
       " '保险丝',\n",
       " '外面',\n",
       " '电磁阀',\n",
       " '或',\n",
       " '意思',\n",
       " '明天',\n",
       " '三元催化',\n",
       " '只是',\n",
       " '曲轴',\n",
       " '读取',\n",
       " '100',\n",
       " '不到',\n",
       " '助力',\n",
       " '氧',\n",
       " '风扇',\n",
       " '这些',\n",
       " '燃油',\n",
       " '电压',\n",
       " '内部',\n",
       " '而且',\n",
       " '容易',\n",
       " '车身',\n",
       " '大灯',\n",
       " '严重',\n",
       " '质量',\n",
       " '漏气',\n",
       " '好像',\n",
       " '关注',\n",
       " '导航',\n",
       " '走',\n",
       " '间隙',\n",
       " '配件',\n",
       " '与',\n",
       " '烧',\n",
       " '4s',\n",
       " '漏油',\n",
       " '像',\n",
       " '引起',\n",
       " '里',\n",
       " '10',\n",
       " '正',\n",
       " '加速',\n",
       " '转向',\n",
       " '玻璃',\n",
       " '反应',\n",
       " '哒',\n",
       " '麻烦',\n",
       " '离合',\n",
       " '特别',\n",
       " '才能',\n",
       " '车门',\n",
       " '哪',\n",
       " '月',\n",
       " '首先',\n",
       " '电子',\n",
       " '5',\n",
       " '完',\n",
       " '分析',\n",
       " '马达',\n",
       " '听',\n",
       " '太',\n",
       " '合成',\n",
       " '一定',\n",
       " '办法',\n",
       " '原车',\n",
       " '挡',\n",
       " '低',\n",
       " '内',\n",
       " '手动',\n",
       " '起步',\n",
       " '电',\n",
       " '别的',\n",
       " '为什么',\n",
       " '帮',\n",
       " '修复',\n",
       " '本身',\n",
       " '费用',\n",
       " '发电机',\n",
       " '热车',\n",
       " '12',\n",
       " '总成',\n",
       " '号',\n",
       " '被',\n",
       " '请',\n",
       " '很多',\n",
       " '有时候',\n",
       " '车型',\n",
       " '必要',\n",
       " '随时',\n",
       " '前面',\n",
       " '刚',\n",
       " '发出',\n",
       " '车主',\n",
       " '重点',\n",
       " '四轮',\n",
       " '存在',\n",
       " '加装',\n",
       " '说明',\n",
       " '喷漆',\n",
       " '突然',\n",
       " '16',\n",
       " '变速器',\n",
       " '开始',\n",
       " '比',\n",
       " '装',\n",
       " '防盗',\n",
       " '希望',\n",
       " '查',\n",
       " '链条',\n",
       " '排气管',\n",
       " '属于',\n",
       " '看到',\n",
       " '数据流',\n",
       " '无法',\n",
       " '调',\n",
       " '报',\n",
       " '调整',\n",
       " '最近',\n",
       " '6',\n",
       " '专用',\n",
       " '必须',\n",
       " '功能',\n",
       " '档位',\n",
       " '15',\n",
       " '回答',\n",
       " '连接',\n",
       " '另外',\n",
       " '灯亮',\n",
       " '型号',\n",
       " '减震器',\n",
       " '下来',\n",
       " '变形',\n",
       " '压',\n",
       " '压缩机',\n",
       " '考虑',\n",
       " '通过',\n",
       " '温器',\n",
       " '啥',\n",
       " '这么',\n",
       " '客气',\n",
       " '一些',\n",
       " '响声',\n",
       " '一会',\n",
       " '弄',\n",
       " '调节',\n",
       " '方面',\n",
       " '那里',\n",
       " '几天',\n",
       " '啦',\n",
       " '效果',\n",
       " '刹车油',\n",
       " '有时',\n",
       " '驾驶',\n",
       " '元',\n",
       " '全',\n",
       " '关闭',\n",
       " '人',\n",
       " '只',\n",
       " '判断',\n",
       " '报警',\n",
       " '怎么办',\n",
       " '注意',\n",
       " '提示',\n",
       " '20',\n",
       " '速度',\n",
       " '堵塞',\n",
       " '放',\n",
       " '倒车',\n",
       " '仪表盘',\n",
       " '放心',\n",
       " '几个',\n",
       " '节',\n",
       " '联系',\n",
       " '排气',\n",
       " '抖',\n",
       " '估计',\n",
       " '最',\n",
       " '电脑板',\n",
       " '减震',\n",
       " '左',\n",
       " '诊断',\n",
       " '代码',\n",
       " '打火',\n",
       " '垫',\n",
       " '修车',\n",
       " '用车',\n",
       " '掉',\n",
       " '前轮',\n",
       " '方向机',\n",
       " '打不着',\n",
       " '早上',\n",
       " '开车',\n",
       " '固定',\n",
       " '方法',\n",
       " '点击',\n",
       " '质保',\n",
       " '就行了',\n",
       " '换挡',\n",
       " '打着',\n",
       " '停车',\n",
       " '觉得',\n",
       " '要是',\n",
       " '目前',\n",
       " '同时',\n",
       " '升',\n",
       " '版',\n",
       " '怎么样',\n",
       " '该',\n",
       " '踩油门',\n",
       " '很大',\n",
       " '大众',\n",
       " '网上',\n",
       " '锁',\n",
       " '到底',\n",
       " '噪音',\n",
       " '懂',\n",
       " '品牌',\n",
       " '发动',\n",
       " '不亮',\n",
       " '任何',\n",
       " '涡轮',\n",
       " '那种',\n",
       " '暖风',\n",
       " '大修',\n",
       " '头像',\n",
       " '灯泡',\n",
       " '购买',\n",
       " '嘛',\n",
       " '单独',\n",
       " '找到',\n",
       " '试一下',\n",
       " '以及',\n",
       " '排除',\n",
       " '高兴',\n",
       " '不足',\n",
       " '毛病',\n",
       " '13',\n",
       " '复位',\n",
       " '测试',\n",
       " '明白',\n",
       " '倒',\n",
       " '洗',\n",
       " '火',\n",
       " '解码器',\n",
       " '选择',\n",
       " '轻微',\n",
       " '机',\n",
       " '一起',\n",
       " '设置',\n",
       " '快',\n",
       " '拿',\n",
       " '状态',\n",
       " '带',\n",
       " '进去',\n",
       " '胎压',\n",
       " '清楚',\n",
       " '如何',\n",
       " '建议您',\n",
       " '行车',\n",
       " '不过',\n",
       " '循环',\n",
       " '这车',\n",
       " '长',\n",
       " '踏板',\n",
       " '差不多',\n",
       " '插',\n",
       " '相关',\n",
       " '以上',\n",
       " '这里',\n",
       " '自动挡',\n",
       " '顿挫',\n",
       " '原来',\n",
       " '水',\n",
       " '全部',\n",
       " '手刹',\n",
       " '干净',\n",
       " '高压',\n",
       " '行',\n",
       " '专业',\n",
       " '14',\n",
       " '发',\n",
       " '免费',\n",
       " '昨天',\n",
       " '积炭',\n",
       " '不好意思',\n",
       " '改装',\n",
       " '由于',\n",
       " '胶套',\n",
       " '异常',\n",
       " '中间',\n",
       " '帮助',\n",
       " '拆开',\n",
       " '有个',\n",
       " '叫',\n",
       " '进',\n",
       " '基本',\n",
       " '11',\n",
       " '油路',\n",
       " '气囊',\n",
       " '操作',\n",
       " '可能性',\n",
       " '松动',\n",
       " '愉快',\n",
       " '搭',\n",
       " '感谢',\n",
       " '清除',\n",
       " '厉害',\n",
       " '电源',\n",
       " '老化',\n",
       " '一年',\n",
       " '电池',\n",
       " '支持',\n",
       " 'ABS',\n",
       " '右',\n",
       " '车速',\n",
       " '怎样',\n",
       " '器',\n",
       " '更',\n",
       " '油压',\n",
       " '老师',\n",
       " '修理店',\n",
       " '照片',\n",
       " '度',\n",
       " '燃烧',\n",
       " '管',\n",
       " '修理',\n",
       " '将',\n",
       " '一根',\n",
       " '拔',\n",
       " '朋友',\n",
       " '水泵',\n",
       " '每次',\n",
       " '缸盖',\n",
       " '漏',\n",
       " '接',\n",
       " '喇叭',\n",
       " '小时',\n",
       " '四个',\n",
       " '能够',\n",
       " '一段时间',\n",
       " '刚才',\n",
       " '后轮',\n",
       " '就要',\n",
       " '部位',\n",
       " '码',\n",
       " '厂家',\n",
       " '4S',\n",
       " '后备箱',\n",
       " '宝马',\n",
       " '完全',\n",
       " '动平衡',\n",
       " '轮毂',\n",
       " '多久',\n",
       " '并',\n",
       " '观察',\n",
       " '升级',\n",
       " '低速',\n",
       " '偶尔',\n",
       " '万',\n",
       " '继续',\n",
       " '停',\n",
       " '当时',\n",
       " '过程',\n",
       " '向',\n",
       " '贵',\n",
       " '三个',\n",
       " '少',\n",
       " '遥控器',\n",
       " '油封',\n",
       " '部件',\n",
       " '拍',\n",
       " '油箱',\n",
       " '刮',\n",
       " '不同',\n",
       " '30',\n",
       " '偏',\n",
       " '盖',\n",
       " '半轴',\n",
       " '图',\n",
       " '线束',\n",
       " '听到',\n",
       " '气缸',\n",
       " '喷',\n",
       " '球头',\n",
       " '换个',\n",
       " '技师',\n",
       " '不够',\n",
       " '事故',\n",
       " '之间',\n",
       " '断',\n",
       " '8',\n",
       " '碳',\n",
       " '没什么',\n",
       " '7',\n",
       " '改',\n",
       " '担心',\n",
       " '进入',\n",
       " '刚刚',\n",
       " '经常',\n",
       " '喷油',\n",
       " '保险杠',\n",
       " '刹车盘',\n",
       " '拆掉',\n",
       " '量',\n",
       " '超过',\n",
       " '试',\n",
       " '清理',\n",
       " '轮',\n",
       " '数',\n",
       " '遥控',\n",
       " '推荐',\n",
       " '变化',\n",
       " '主',\n",
       " '产生',\n",
       " '后来',\n",
       " '及时',\n",
       " '学习',\n",
       " '动',\n",
       " '断电',\n",
       " '确认',\n",
       " '无',\n",
       " '谢谢您',\n",
       " '要求',\n",
       " '颜色',\n",
       " '拉',\n",
       " '这边',\n",
       " '试车',\n",
       " '非常',\n",
       " '车上',\n",
       " '怕',\n",
       " '测',\n",
       " '排量',\n",
       " '不错',\n",
       " '座椅',\n",
       " '解决问题',\n",
       " '热',\n",
       " '电路',\n",
       " '牌子',\n",
       " '怀疑',\n",
       " '不响',\n",
       " '遇到',\n",
       " '副',\n",
       " '拉杆',\n",
       " '大约',\n",
       " '手动挡',\n",
       " '右边',\n",
       " '上次',\n",
       " '95',\n",
       " '添加',\n",
       " '可是',\n",
       " '提速',\n",
       " '平时',\n",
       " '拔掉',\n",
       " '读',\n",
       " '嘉实多',\n",
       " '几次',\n",
       " '短路',\n",
       " '包括',\n",
       " '增压',\n",
       " '钣金',\n",
       " '别克',\n",
       " '确实',\n",
       " '是因为',\n",
       " '分泵',\n",
       " '作用',\n",
       " '天窗',\n",
       " '修好',\n",
       " '半',\n",
       " '稳定',\n",
       " '帮到',\n",
       " '电阻',\n",
       " '转动',\n",
       " '不管',\n",
       " '可',\n",
       " '安全',\n",
       " '店里',\n",
       " '美孚',\n",
       " '按照',\n",
       " '失火',\n",
       " '路',\n",
       " '最后',\n",
       " '09',\n",
       " '单元',\n",
       " '中控',\n",
       " '水管',\n",
       " '堵',\n",
       " '四',\n",
       " '机滤',\n",
       " '祝您',\n",
       " '悬挂',\n",
       " '按键',\n",
       " '17',\n",
       " '稍微',\n",
       " '程序',\n",
       " '供电',\n",
       " '排',\n",
       " '高温',\n",
       " '还要',\n",
       " '左边',\n",
       " '负极',\n",
       " '松',\n",
       " '气阀',\n",
       " '片',\n",
       " '检修',\n",
       " '所有',\n",
       " '发生',\n",
       " '3000',\n",
       " '急',\n",
       " '齿轮',\n",
       " '冬天',\n",
       " '有些',\n",
       " 'D',\n",
       " '性能',\n",
       " '没用',\n",
       " '废',\n",
       " '刚换',\n",
       " '上去',\n",
       " '就行',\n",
       " '没换',\n",
       " '进气道',\n",
       " '其它',\n",
       " '电话',\n",
       " '过来',\n",
       " '搞',\n",
       " '增加',\n",
       " '没电',\n",
       " '模式',\n",
       " '便宜',\n",
       " '记号',\n",
       " '除了',\n",
       " '按钮',\n",
       " '丰田',\n",
       " '鼓风机',\n",
       " '来说',\n",
       " '事',\n",
       " '润滑',\n",
       " '各位',\n",
       " '里程',\n",
       " '漆',\n",
       " '40',\n",
       " '拆卸',\n",
       " '告诉',\n",
       " '声',\n",
       " '慢慢',\n",
       " '当地',\n",
       " '挂挡',\n",
       " '管子',\n",
       " '5000',\n",
       " '们',\n",
       " '下降',\n",
       " '不用谢',\n",
       " 'abs',\n",
       " '进气管',\n",
       " '比如',\n",
       " '撞',\n",
       " '接触',\n",
       " '漏水',\n",
       " '合适',\n",
       " '回',\n",
       " '回复',\n",
       " '消失',\n",
       " '求',\n",
       " '而',\n",
       " '方便',\n",
       " '后期',\n",
       " '混合气',\n",
       " '分钟',\n",
       " '两根',\n",
       " '前后',\n",
       " '副驾驶',\n",
       " '密封',\n",
       " '卖',\n",
       " '18',\n",
       " '整个',\n",
       " '老',\n",
       " '起',\n",
       " '达到',\n",
       " '开着',\n",
       " '起动',\n",
       " '工具',\n",
       " '顶',\n",
       " '原地',\n",
       " '图文',\n",
       " '300',\n",
       " '支架',\n",
       " '及',\n",
       " '机械',\n",
       " '打滑',\n",
       " '阀',\n",
       " '哪些',\n",
       " '摩擦',\n",
       " '起动机',\n",
       " '进水',\n",
       " '冷却液',\n",
       " '挺',\n",
       " '脏',\n",
       " '阀体',\n",
       " '一键',\n",
       " '回来',\n",
       " '冒',\n",
       " '雷达',\n",
       " '雨',\n",
       " '简单',\n",
       " '无力',\n",
       " '缺缸',\n",
       " '盒',\n",
       " '到位',\n",
       " '专用工具',\n",
       " '晚上',\n",
       " '那些',\n",
       " '好好',\n",
       " '卡',\n",
       " '奔驰',\n",
       " '震动',\n",
       " '跳',\n",
       " '天气',\n",
       " '粘度',\n",
       " '空挡',\n",
       " '一对一',\n",
       " '往',\n",
       " '弹簧',\n",
       " '请教',\n",
       " '油底壳',\n",
       " '盖子',\n",
       " '80',\n",
       " '一体',\n",
       " '分离',\n",
       " '～',\n",
       " '找个',\n",
       " '二手车',\n",
       " '吹',\n",
       " '手机',\n",
       " '升降',\n",
       " '92',\n",
       " '一种',\n",
       " '之类',\n",
       " '接触不良',\n",
       " '黑色',\n",
       " '冷',\n",
       " '臂',\n",
       " '护板',\n",
       " '运转',\n",
       " '保险盒',\n",
       " '燃烧室',\n",
       " '问问',\n",
       " '两',\n",
       " '总泵',\n",
       " '板',\n",
       " '更好',\n",
       " '室盖',\n",
       " '范围',\n",
       " '打不开',\n",
       " '共振',\n",
       " '一缸',\n",
       " '普通',\n",
       " '个人',\n",
       " '塑料',\n",
       " '拆装',\n",
       " '慢',\n",
       " '提供',\n",
       " '一块',\n",
       " '08',\n",
       " '我车',\n",
       " '充电',\n",
       " '空滤',\n",
       " '漏电',\n",
       " '保修',\n",
       " '轴',\n",
       " '轮子',\n",
       " '管路',\n",
       " '旁边',\n",
       " '机器',\n",
       " '拉线',\n",
       " '路面',\n",
       " '基本上',\n",
       " '视频',\n",
       " '设备',\n",
       " '标准',\n",
       " '清洗剂',\n",
       " '箱',\n",
       " '附近',\n",
       " '灯不亮',\n",
       " '没关系',\n",
       " '准确',\n",
       " '即可',\n",
       " '换油',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model.wv.index2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 数值转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遇到未知词就填充unk的索引\n",
    "unk_index = vocab['<UNK>']\n",
    "def transform_data(sentence,vocab):\n",
    "    # 字符串切分成词\n",
    "    words=sentence.split(' ')\n",
    "    # 按照vocab的index进行转换\n",
    "    ids=[vocab[word] if word in vocab else unk_index for word in words]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将词转换成索引  [<START> 方向机 重 ...] -> [32800, 403, 986, 246, 231\n",
    "train_ids_x=train_X.apply(lambda x:transform_data(x,vocab))\n",
    "train_ids_y=train_Y.apply(lambda x:transform_data(x,vocab))\n",
    "test_ids_x=test_X.apply(lambda x:transform_data(x,vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [33230, 4, 0, 1198, 347, 34, 474, 474, 103, 8,...\n",
       "1    [33230, 291, 18, 80, 154, 2, 22, 37, 291, 102,...\n",
       "2    [33230, 1198, 6429, 649, 134, 1, 789, 35, 216,...\n",
       "3    [33230, 20, 339, 25, 3, 21, 7054, 273, 20, 232...\n",
       "4    [33230, 103, 3093, 4574, 23641, 1, 33231, 1, 1...\n",
       "Name: X, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将索引列表转换成矩阵 [32800, 403, 986, 246, 231] --> array([[32800,   403,   986 ]]\n",
    "train_data_X=np.array(train_ids_x.tolist())\n",
    "train_data_Y=np.array(train_ids_y.tolist())\n",
    "test_data_X=np.array(test_ids_x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82871, 406)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 简易模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq(input_length, output_sequence_length, embedding_matrix, vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=300, weights=[embedding_matrix], trainable=False,\n",
    "                        input_length=input_length))\n",
    "    model.add(Bidirectional(GRU(300, return_sequences=False)))\n",
    "    model.add(Dense(300, activation=\"relu\"))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(Bidirectional(GRU(300, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(1e-3))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 基本参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82871, 406)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入的长度\n",
    "input_length = train_data_X.shape[1]\n",
    "# 输出的长度\n",
    "output_sequence_length = train_data_Y.shape[1]\n",
    "# 词表大小\n",
    "vocab_size=len(vocab)\n",
    "# 词向量矩阵\n",
    "embedding_matrix = wv_model.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 406, 300)          9970200   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 600)               1083600   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 46, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 46, 600)           1083600   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 46, 33234)         19973634  \n",
      "=================================================================\n",
      "Total params: 32,291,334\n",
      "Trainable params: 22,321,134\n",
      "Non-trainable params: 9,970,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = seq2seq(input_length,output_sequence_length,embedding_matrix,vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66296 samples, validate on 16575 samples\n",
      "   32/66296 [..............................] - ETA: 2:52:08"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/bidirectional/forward_gru/StatefulPartitionedCall]] [Op:__inference_distributed_function_10189]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-aa1eef2f16ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Installer-software\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/bidirectional/forward_gru/StatefulPartitionedCall]] [Op:__inference_distributed_function_10189]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data_X, train_data_Y, batch_size=32, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('data/seq2seq_model.h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 .5 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_Y = model.predict(test_data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 所有输出端，都以一个通用的<start>标记开头，以<end>标记结尾，这两个标记也视为一个词/字；\n",
    "\n",
    "2. 将<start>输入decoder，然后得到隐藏层向量，将这个向量与encoder的输出混合，然后送入一个分类器，分类器的结果应当输出P；\n",
    "\n",
    "3. 将P输入decoder，得到新的隐藏层向量，再次与encoder的输出混合，送入分类器，分类器应输出Q；\n",
    "\n",
    "4. 依此递归，直到分类器的结果输出<end>。\n",
    "    \n",
    "\n",
    "* 回到用seq2seq生成文章标题这个任务上，模型可以做些简化，并且可以引入一些先验知识。比如，由于输入语言和输出语言都是中文，因此encoder和decoder的Embedding层可以共享参数（也就是用同一套词向量）。这使得模型的参数量大幅度减少了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer # 词表构建 单词过滤 词频统计 序列填充\n",
    "from keras.preprocessing.sequence import pad_sequences # 序列数据填充\n",
    "from sklearn.model_selection import train_test_split # 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q4 新加的符号不在词表 和 词向量矩阵中,怎么办?\n",
    "\n",
    "## 3.4 词表更新\n",
    "\n",
    "print('start retrain w2v model')\n",
    "wv_model.build_vocab(LineSentence(train_x_pad_path), update=True)\n",
    "wv_model.train(LineSentence(train_x_pad_path), epochs=wv_train_epochs, total_examples=wv_model.corpus_count)\n",
    "print('1/3')\n",
    "wv_model.build_vocab(LineSentence(train_y_pad_path), update=True)\n",
    "wv_model.train(LineSentence(train_y_pad_path), epochs=wv_train_epochs, total_examples=wv_model.corpus_count)\n",
    "print('2/3')\n",
    "wv_model.build_vocab(LineSentence(test_x_pad_path), update=True)\n",
    "wv_model.train(LineSentence(test_x_pad_path), epochs=wv_train_epochs, total_examples=wv_model.corpus_count)\n",
    "\n",
    "# 保存词向量模型\n",
    "wv_model.save(save_wv_model_path)\n",
    "\n",
    "## Q5.为什么不一开始就添加 标志符号,然后训练词向量?\n",
    "\n",
    " 更新vocab \n",
    "vocab = {word: index for index, word in enumerate(wv_model.wv.index2word)}\n",
    "reverse_vocab = {index: word for index, word in enumerate(wv_model.wv.index2word)}\n",
    "# 更新词向量矩阵\n",
    "embedding_matrix = wv_model.wv.vectors\n",
    "embedding_matrix.shape#\n",
    "\n",
    "## Q6. 词可以训练吗?\n",
    "\n",
    "train_df['X'].head()\n",
    "\n",
    "## 3.4 数值转换\n",
    "\n",
    "# 遇到未知词就填充unk的索引\n",
    "unk_index = vocab['<UNK>']\n",
    "def transform_data(sentence,vocab):\n",
    "    # 字符串切分成词\n",
    "    words=sentence.split(' ')\n",
    "    # 按照vocab的index进行转换\n",
    "    ids=[vocab[word] if word in vocab else unk_index for word in words]\n",
    "    return ids\n",
    "\n",
    "# 将词转换成索引  [<START> 方向机 重 ...] -> [32800, 403, 986, 246, 231\n",
    "train_ids_x=train_df['X'].apply(lambda x:transform_data(x,vocab))\n",
    "train_ids_y=train_df['Y'].apply(lambda x:transform_data(x,vocab))\n",
    "test_ids_x=test_df['X'].apply(lambda x:transform_data(x,vocab))\n",
    "\n",
    "# 将索引列表转换成矩阵 [32800, 403, 986, 246, 231] --> array([[32800,   403,   986 ]]\n",
    "train_data_X=np.array(train_ids_x.tolist())\n",
    "train_data_Y=np.array(train_ids_y.tolist())\n",
    "test_data_X=np.array(test_ids_x.tolist())\n",
    "\n",
    "train_data_X.shape\n",
    "\n",
    "## 4. 简易模型搭建\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "def seq2seq(input_length, output_sequence_length, embedding_matrix, vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=300, weights=[embedding_matrix], trainable=False,\n",
    "                        input_length=input_length))\n",
    "    model.add(Bidirectional(GRU(300, return_sequences=False)))\n",
    "    model.add(Dense(300, activation=\"relu\"))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(Bidirectional(GRU(300, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(1e-3))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "## 4.1 基本参数设置\n",
    "\n",
    "train_data_X.shape\n",
    "\n",
    "# 输入的长度\n",
    "input_length = train_data_X.shape[1]\n",
    "# 输出的长度\n",
    "output_sequence_length = train_data_Y.shape[1]\n",
    "# 词表大小\n",
    "vocab_size=len(vocab)\n",
    "# 词向量矩阵\n",
    "embedding_matrix = wv_model.wv.vectors\n",
    "\n",
    "## 4.2 模型构建\n",
    "\n",
    "model = seq2seq(input_length,output_sequence_length,embedding_matrix,vocab_size)\n",
    "\n",
    "## 4.3 模型训练\n",
    "\n",
    "model.fit(train_data_X, train_data_Y, batch_size=32, epochs=1, validation_split=0.2)\n",
    "\n",
    "## 4.4 模型保存\n",
    "\n",
    "model.save('data/seq2seq_model.h')\n",
    "\n",
    "## 4 .5 模型预测\n",
    "\n",
    "test_data_Y = model.predict(test_data_X)\n",
    "\n",
    "# seq2seq\n",
    "\n",
    "1. 所有输出端，都以一个通用的<start>标记开头，以<end>标记结尾，这两个标记也视为一个词/字；\n",
    "\n",
    "2. 将<start>输入decoder，然后得到隐藏层向量，将这个向量与encoder的输出混合，然后送入一个分类器，分类器的结果应当输出P；\n",
    "\n",
    "3. 将P输入decoder，得到新的隐藏层向量，再次与encoder的输出混合，送入分类器，分类器应输出Q；\n",
    "\n",
    "4. 依此递归，直到分类器的结果输出<end>。\n",
    "    \n",
    "\n",
    "* 回到用seq2seq生成文章标题这个任务上，模型可以做些简化，并且可以引入一些先验知识。比如，由于输入语言和输出语言都是中文，因此encoder和decoder的Embedding层可以共享参数（也就是用同一套词向量）。这使得模型的参数量大幅度减少了。\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer # 词表构建 单词过滤 词频统计 序列填充\n",
    "from keras.preprocessing.sequence import pad_sequences # 序列数据填充\n",
    "from sklearn.model_selection import train_test_split # 数据集划分"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
